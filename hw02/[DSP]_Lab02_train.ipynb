{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH1uJ39uaS1r",
        "outputId": "4dd2718b-a892-49d3-ea60-32b66e19d656"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qz79pmW5JIR2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-25 13:29:00.373373: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-25 13:29:03.242083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pigeon_gcc/anaconda3/envs/iu_ss/lib/\n",
            "2023-02-25 13:29:03.242335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/pigeon_gcc/anaconda3/envs/iu_ss/lib/\n",
            "2023-02-25 13:29:03.242362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib\n",
        "import keras.backend as K\n",
        "matplotlib.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HP_u6-uHJIR4"
      },
      "outputs": [],
      "source": [
        "IMAGE_SHAPE = (400, 300)\n",
        "TRAINING_DATA_DIR = 'aug/training/'\n",
        "VALID_DATA_DIR = 'aug/validation/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i74wKFLSJIR5",
        "outputId": "3e492590-c770-4ea7-84cc-9c99db2a52f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3557 images belonging to 2 classes.\n",
            "Found 546 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ")\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE,\n",
        ")\n",
        "valid_generator = datagen.flow_from_directory(\n",
        "    VALID_DATA_DIR,\n",
        "    shuffle=False,\n",
        "    target_size=IMAGE_SHAPE,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "L_-Sog8bJIR6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-25 13:29:06.642480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:06.663480: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:06.664160: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:06.666245: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-02-25 13:29:06.667352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:06.667998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:06.668587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:08.518880: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:08.519565: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:08.520107: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-02-25 13:29:08.520583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4554 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "def build_model(num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', \n",
        "                           input_shape=(400, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "model = build_model(num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WoLjvn7cJIR7"
      },
      "outputs": [],
      "source": [
        "def get_f1(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    \n",
        "    return f1_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIeSKJ8qJIR8",
        "outputId": "20198b20-b458-4e05-aa7e-4e93cd44fde6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 398, 298, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 199, 149, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 197, 147, 16)      2320      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 98, 73, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 96, 71, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 48, 35, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 53760)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1720352   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,727,826\n",
            "Trainable params: 1,727,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[get_f1]\n",
        ")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REypIz2bJIR9",
        "outputId": "87dbbd7f-0d9d-4fd1-9011-51a5962ba4ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-02-25 13:29:13.131881: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
            "2023-02-25 13:29:14.427302: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f09e8011930 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-02-25 13:29:14.427332: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
            "2023-02-25 13:29:14.431799: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-02-25 13:29:14.567231: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "111/111 [==============================] - 22s 152ms/step - loss: 0.7053 - get_f1: 0.5248 - val_loss: 0.6927 - val_get_f1: 0.5147\n",
            "Epoch 2/30\n",
            "111/111 [==============================] - 15s 139ms/step - loss: 0.6931 - get_f1: 0.5102 - val_loss: 0.6942 - val_get_f1: 0.4871\n",
            "Epoch 3/30\n",
            "111/111 [==============================] - 26s 232ms/step - loss: 0.6937 - get_f1: 0.5302 - val_loss: 0.6946 - val_get_f1: 0.4945\n",
            "Epoch 4/30\n",
            "111/111 [==============================] - 48s 429ms/step - loss: 0.6851 - get_f1: 0.5486 - val_loss: 0.6976 - val_get_f1: 0.5276\n",
            "Epoch 5/30\n",
            "111/111 [==============================] - 18s 164ms/step - loss: 0.6623 - get_f1: 0.6130 - val_loss: 0.7027 - val_get_f1: 0.5441\n",
            "Epoch 6/30\n",
            "111/111 [==============================] - 17s 150ms/step - loss: 0.6610 - get_f1: 0.6221 - val_loss: 0.7003 - val_get_f1: 0.5533\n",
            "Epoch 7/30\n",
            "111/111 [==============================] - 48s 434ms/step - loss: 0.5691 - get_f1: 0.6939 - val_loss: 0.6433 - val_get_f1: 0.5956\n",
            "Epoch 8/30\n",
            "111/111 [==============================] - 26s 233ms/step - loss: 0.4238 - get_f1: 0.7911 - val_loss: 0.6212 - val_get_f1: 0.6967\n",
            "Epoch 9/30\n",
            "111/111 [==============================] - 16s 146ms/step - loss: 0.3356 - get_f1: 0.8497 - val_loss: 0.5811 - val_get_f1: 0.7390\n",
            "Epoch 10/30\n",
            "111/111 [==============================] - 25s 228ms/step - loss: 0.2324 - get_f1: 0.9085 - val_loss: 0.5350 - val_get_f1: 0.7647\n",
            "Epoch 11/30\n",
            "111/111 [==============================] - 47s 421ms/step - loss: 0.2846 - get_f1: 0.8756 - val_loss: 0.6420 - val_get_f1: 0.7224\n",
            "Epoch 12/30\n",
            "111/111 [==============================] - 18s 157ms/step - loss: 0.1936 - get_f1: 0.9243 - val_loss: 0.5222 - val_get_f1: 0.8290\n",
            "Epoch 13/30\n",
            "111/111 [==============================] - 13s 114ms/step - loss: 0.1686 - get_f1: 0.9431 - val_loss: 0.4926 - val_get_f1: 0.8548\n",
            "Epoch 14/30\n",
            "111/111 [==============================] - 15s 138ms/step - loss: 0.1189 - get_f1: 0.9569 - val_loss: 0.5305 - val_get_f1: 0.8438\n",
            "Epoch 15/30\n",
            "111/111 [==============================] - 59s 532ms/step - loss: 0.0771 - get_f1: 0.9735 - val_loss: 0.5504 - val_get_f1: 0.8695\n",
            "Epoch 16/30\n",
            "111/111 [==============================] - 20s 179ms/step - loss: 0.0729 - get_f1: 0.9734 - val_loss: 0.5948 - val_get_f1: 0.8364\n",
            "Epoch 17/30\n",
            "111/111 [==============================] - 18s 158ms/step - loss: 0.0615 - get_f1: 0.9825 - val_loss: 0.6394 - val_get_f1: 0.8658\n",
            "Epoch 18/30\n",
            "111/111 [==============================] - 50s 449ms/step - loss: 0.0313 - get_f1: 0.9918 - val_loss: 0.6703 - val_get_f1: 0.8805\n",
            "Epoch 19/30\n",
            "111/111 [==============================] - 24s 216ms/step - loss: 0.0259 - get_f1: 0.9938 - val_loss: 0.6693 - val_get_f1: 0.8750\n",
            "Epoch 20/30\n",
            "111/111 [==============================] - 17s 150ms/step - loss: 0.0283 - get_f1: 0.9944 - val_loss: 0.8689 - val_get_f1: 0.8658\n",
            "Epoch 21/30\n",
            "111/111 [==============================] - 38s 344ms/step - loss: 0.0249 - get_f1: 0.9947 - val_loss: 0.6398 - val_get_f1: 0.8897\n",
            "Epoch 22/30\n",
            "111/111 [==============================] - 36s 326ms/step - loss: 0.0416 - get_f1: 0.9913 - val_loss: 0.6054 - val_get_f1: 0.8805\n",
            "Epoch 23/30\n",
            "111/111 [==============================] - 17s 153ms/step - loss: 0.0117 - get_f1: 0.9983 - val_loss: 0.6750 - val_get_f1: 0.8934\n",
            "Epoch 24/30\n",
            "111/111 [==============================] - 19s 167ms/step - loss: 0.0076 - get_f1: 0.9989 - val_loss: 0.7504 - val_get_f1: 0.8952\n",
            "Epoch 25/30\n",
            "111/111 [==============================] - 55s 498ms/step - loss: 0.0032 - get_f1: 1.0000 - val_loss: 0.7805 - val_get_f1: 0.8897\n",
            "Epoch 26/30\n",
            "111/111 [==============================] - 19s 166ms/step - loss: 0.0020 - get_f1: 1.0000 - val_loss: 0.8103 - val_get_f1: 0.8879\n",
            "Epoch 27/30\n",
            "111/111 [==============================] - 17s 151ms/step - loss: 0.0016 - get_f1: 1.0000 - val_loss: 0.8292 - val_get_f1: 0.8934\n",
            "Epoch 28/30\n",
            "111/111 [==============================] - 46s 417ms/step - loss: 0.0014 - get_f1: 1.0000 - val_loss: 0.8538 - val_get_f1: 0.8934\n",
            "Epoch 29/30\n",
            "111/111 [==============================] - 27s 241ms/step - loss: 0.0012 - get_f1: 1.0000 - val_loss: 0.8790 - val_get_f1: 0.8934\n",
            "Epoch 30/30\n",
            "111/111 [==============================] - 17s 149ms/step - loss: 0.0010 - get_f1: 1.0000 - val_loss: 0.8984 - val_get_f1: 0.8952\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.samples // BATCH_SIZE // 2,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=valid_generator,\n",
        "                    validation_steps= valid_generator.samples // BATCH_SIZE // 2,\n",
        "                    verbose=1\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1RBZeOfqJISA"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Artem_Chernitsa/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Artem_Chernitsa/assets\n"
          ]
        }
      ],
      "source": [
        "# model.save_weights('Artem_Chernitsa')\n",
        "model.save('Artem_Chernitsa')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SzrWiXPEgjaB"
      },
      "outputs": [],
      "source": [
        "# !tar czf Artem_Chernitsa.tar Artem_Chernitsa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fR4s5BO3TXpo"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# image = tf.keras.preprocessing.image.load_img(r\"/content/test_barbie/test_barbie.jpg\",\n",
        "#                                               target_size=(640, 480))\n",
        "# input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "# input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "# input_arr = input_arr.astype('float32') / 255.  # This is VERY important\n",
        "\n",
        "\n",
        "# predictions = model.predict(input_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gFZk7ugOWkAY"
      },
      "outputs": [],
      "source": [
        "# predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lQv8L3YWW0Pb"
      },
      "outputs": [],
      "source": [
        "# train_generator.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "z9GddIXzWisT"
      },
      "outputs": [],
      "source": [
        "# predicted_class = np.argmax(predictions, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Rn33l2zlWncc"
      },
      "outputs": [],
      "source": [
        "# predicted_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mUi-zhCEY9u9"
      },
      "outputs": [],
      "source": [
        "# image = tf.keras.preprocessing.image.load_img(r\"/content/test_puppy.jpg\",\n",
        "#                                               target_size=(640, 480))\n",
        "# input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
        "# input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
        "# input_arr = input_arr.astype('float32') / 255.  # This is VERY important\n",
        "\n",
        "\n",
        "# predictions = model.predict(input_arr)\n",
        "# predicted_class = np.argmax(predictions, axis=-1)\n",
        "# print(predictions)\n",
        "# print(predicted_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nH2aR-vZdudq"
      },
      "outputs": [],
      "source": [
        "# model2 = tf.keras.models.load_model('/content/Artem_Chernitsa', compile=False)\n",
        "# predictions = model2.predict(input_arr)\n",
        "# predicted_class = np.argmax(predictions, axis=-1)\n",
        "# print(predictions)\n",
        "# print(predicted_class)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "iu_ss",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3f74aba6cf40f3b26d20c5f496f2ca9cfd53f73da88ce73e69c181fd088147da"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
